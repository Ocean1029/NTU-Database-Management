{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Incase you don't have faker installed\n",
    "! pip3 install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     user_id         username    password                       email  \\\n",
      "0          1         johnhall  et&6Z0iN!A   martinezrobin@example.com   \n",
      "1          2      gentrykayla  EFMjSfon^5       william63@example.com   \n",
      "2          3     peternavarro  *pcTOYdim7       alawrence@example.org   \n",
      "3          4    lauramckinney  a^8&Hxwe_G       stephen67@example.net   \n",
      "4          5          kelly49  Y(B9YfVy7y        donald06@example.org   \n",
      "..       ...              ...         ...                         ...   \n",
      "995      996    joshuaalvarez  &4IElHLhpJ    smithmichael@example.com   \n",
      "996      997        matthew30  3We46J7w^P   powersjessica@example.com   \n",
      "997      998           dortiz  #sSPFwXI^3  danielleflores@example.net   \n",
      "998      999  bennettjennifer  Z5UXKpWh%1       uwilliams@example.net   \n",
      "999     1000      johnsoneric  K2vEfqto!c          drew63@example.org   \n",
      "\n",
      "                     phone       role  created_at  \n",
      "0    001-500-953-0257x9437       user  2022-03-27  \n",
      "1          +1-335-722-5291       user  2021-08-21  \n",
      "2         691.783.2374x176       user  2023-04-02  \n",
      "3    +1-393-953-9608x84388  organizer  2023-12-20  \n",
      "4       833.977.1495x58778       user  2020-09-11  \n",
      "..                     ...        ...         ...  \n",
      "995             7958858215       user  2021-06-03  \n",
      "996    +1-802-523-8513x616       user  2022-03-28  \n",
      "997     342.284.2374x24743      admin  2024-07-07  \n",
      "998     405.527.8762x08556       user  2023-05-22  \n",
      "999           757-249-4711  organizer  2024-06-24  \n",
      "\n",
      "[1000 rows x 7 columns]\n",
      "Admin Users: 118\n",
      "User Users: 695\n",
      "Organizer Users: 187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/wcg3qcf14tjcjw_8md95qf_m0000gn/T/ipykernel_32579/3940419191.py:38: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  admin_users = users_df[users_df['role'] == 'admin'].count()[0]\n",
      "/var/folders/p_/wcg3qcf14tjcjw_8md95qf_m0000gn/T/ipykernel_32579/3940419191.py:39: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  user_users = users_df[users_df['role'] == 'user'].count()[0]\n",
      "/var/folders/p_/wcg3qcf14tjcjw_8md95qf_m0000gn/T/ipykernel_32579/3940419191.py:40: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  organizer_users = users_df[users_df['role'] == 'organizer'].count()[0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Global Variables\n",
    "user_num = 1000\n",
    "venue_num = 20\n",
    "event_num = 300\n",
    "payment_num = 1400\n",
    "order_num = 1200\n",
    "ticket_num = 1000\n",
    "seat_num = 200\n",
    "venues = []\n",
    "\n",
    "# Users\n",
    "users = []\n",
    "roles = ['admin', 'user', 'organizer']\n",
    "weights = [0.1, 0.7, 0.2]\n",
    "for i in range(1, user_num + 1):\n",
    "    user = {\n",
    "        \"user_id\": i,\n",
    "        \"username\": fake.user_name(),\n",
    "        \"password\": fake.password(),\n",
    "        \"email\": fake.email(),\n",
    "        \"phone\": fake.phone_number(),\n",
    "        \"role\": random.choices(roles, weights)[0],\n",
    "        \"created_at\": fake.date_this_decade()\n",
    "    }\n",
    "    users.append(user)\n",
    "    \n",
    "users_df = pd.DataFrame(users)\n",
    "users_df.to_csv(\"users.csv\", index=False)\n",
    "print(users_df)\n",
    "\n",
    "# Some variables\n",
    "admin_users = users_df[users_df['role'] == 'admin'].count()[0]\n",
    "user_users = users_df[users_df['role'] == 'user'].count()[0]\n",
    "organizer_users = users_df[users_df['role'] == 'organizer'].count()[0]\n",
    "organizers = users_df[users_df['role'] == 'organizer']\n",
    "\n",
    "print(f\"Admin Users: {admin_users}\")\n",
    "print(f\"User Users: {user_users}\")\n",
    "print(f\"Organizer Users: {organizer_users}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    venue_id                    venue_name  \\\n",
      "0          1                   Camacho Inc   \n",
      "1          2     Hall, Johnson and Griffin   \n",
      "2          3                  Sullivan Ltd   \n",
      "3          4                   Gilbert LLC   \n",
      "4          5               Gonzalez-Miller   \n",
      "5          6            Mcclure-Livingston   \n",
      "6          7         Rowe, Smith and Combs   \n",
      "7          8   Poole, Summers and Anderson   \n",
      "8          9  Moses, Contreras and Estrada   \n",
      "9         10                 Montoya-Davis   \n",
      "10        11      Barnes, Cohen and Hansen   \n",
      "11        12                Jones-Anderson   \n",
      "12        13               Walker and Sons   \n",
      "13        14              Williams-Russell   \n",
      "14        15     Peterson, Shaffer and Fox   \n",
      "15        16   Powell, Walker and Castillo   \n",
      "16        17        Velez, Baker and Perry   \n",
      "17        18                   Sharp-Jones   \n",
      "18        19                  Hughes-Allen   \n",
      "19        20                    Berger PLC   \n",
      "\n",
      "                                              address               city  \\\n",
      "0   77628 Davis Corner\\nSouth Jennifermouth, VA 69415          Port Chad   \n",
      "1                           USNS Spears\\nFPO AP 01656      North Crystal   \n",
      "2                           USNS Miller\\nFPO AE 64575           Tinaland   \n",
      "3              41579 Mathis Flat\\nGarciaton, MS 13053  East Jenniferbury   \n",
      "4   715 Theodore Harbors Apt. 055\\nColleenburgh, G...       Port Bridget   \n",
      "5     2632 Salazar Club\\nNorth Jessicahaven, LA 12378        North Tracy   \n",
      "6           88298 Short Track\\nSouth Dalton, RI 38196          Jamesberg   \n",
      "7                    Unit 7180 Box 9130\\nDPO AE 66348    East Jesseville   \n",
      "8   103 Thomas Causeway Apt. 814\\nJennastad, PR 17808   Lake Benjaminton   \n",
      "9          742 Rich Pass\\nSouth Christopher, WY 52472     Daughertyburgh   \n",
      "10  2930 Stephanie Circles Suite 218\\nEricborough,...      Rachelborough   \n",
      "11  75676 Martinez Locks Suite 667\\nLake Suzanne, ...        Melissafort   \n",
      "12                   PSC 5963, Box 6340\\nAPO AE 68367         Port Sarah   \n",
      "13  462 Arthur Green Suite 226\\nLake Brooke, CA 36262         Bensonfurt   \n",
      "14  8339 Howard Expressway Suite 172\\nAndersenstad...    Trujillochester   \n",
      "15  44369 Moore Pike Suite 556\\nMercadoland, AR 63092        Lake Brandy   \n",
      "16  70109 Theresa Key Suite 603\\nSouth Susanberg, ...         New Melvin   \n",
      "17  869 Livingston Mews Apt. 882\\nWest Paul, IA 70229      Jenniferburgh   \n",
      "18  065 Rachel Knolls Apt. 642\\nSouth Christophers...     Port Kylehaven   \n",
      "19      738 Willis Vista\\nNorth Valeriebury, PR 82574          East Ross   \n",
      "\n",
      "    capacity  \n",
      "0       6841  \n",
      "1       6202  \n",
      "2       7507  \n",
      "3       2650  \n",
      "4       3692  \n",
      "5       1295  \n",
      "6       4644  \n",
      "7       7893  \n",
      "8       8546  \n",
      "9       8982  \n",
      "10      6376  \n",
      "11      5027  \n",
      "12      3517  \n",
      "13      3963  \n",
      "14      5294  \n",
      "15      2630  \n",
      "16      7303  \n",
      "17      2441  \n",
      "18      8629  \n",
      "19      9173  \n"
     ]
    }
   ],
   "source": [
    "# Venues\n",
    "for i in range(1, venue_num + 1):\n",
    "    venues.append({\n",
    "        \"venue_id\": i,\n",
    "        \"venue_name\": fake.company(),\n",
    "        \"address\": fake.address(),\n",
    "        \"city\": fake.city(),\n",
    "        \"capacity\": random.randint(1000, 10000)\n",
    "    })\n",
    "venues_df = pd.DataFrame(venues)\n",
    "venues_df.to_csv(\"venues.csv\", index=False)\n",
    "\n",
    "print(venues_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     event_id                                event_name  \\\n",
      "0           1             Seamless national methodology   \n",
      "1           2         Networked bi-directional intranet   \n",
      "2           3       Open-source upward-trending archive   \n",
      "3           4  Public-key context-sensitive parallelism   \n",
      "4           5          Right-sized uniform installation   \n",
      "..        ...                                       ...   \n",
      "295       296             Streamlined composite product   \n",
      "296       297  Profound zero administration utilization   \n",
      "297       298           Synergized interactive protocol   \n",
      "298       299   Multi-channeled tertiary knowledge user   \n",
      "299       300                 Persistent didactic model   \n",
      "\n",
      "                 performer  event_date  venue_id  organizer_id     status  \n",
      "0              Maria Meyer  2024-11-08        11           932  Scheduled  \n",
      "1          Natasha Jackson  2024-06-28         9            73  Completed  \n",
      "2         Victoria Kennedy  2024-11-28         4           976  Scheduled  \n",
      "3          Steven Sandoval  2024-03-10         8            85  Scheduled  \n",
      "4                Ryan Diaz  2024-08-15        17           976  Scheduled  \n",
      "..                     ...         ...       ...           ...        ...  \n",
      "295          Jennifer Hood  2024-10-09        20           958  Scheduled  \n",
      "296       Catherine Rivera  2024-10-29         9           451  Scheduled  \n",
      "297             Heidi Ward  2024-01-13        14           765  Scheduled  \n",
      "298             Mary Blake  2024-07-13        17           180  Scheduled  \n",
      "299  Mr. Christopher Price  2024-03-18        12           893  Scheduled  \n",
      "\n",
      "[300 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Events\n",
    "events = []\n",
    "statuses = [\"Scheduled\", \"Canceled\", \"Completed\"]\n",
    "statuses_weights = [0.7, 0.1, 0.2]\n",
    "for i in range(1, event_num + 1):\n",
    "    events.append({\n",
    "        \"event_id\": i,\n",
    "        \"event_name\": fake.catch_phrase(),\n",
    "        \"performer\": fake.name(),\n",
    "        \"event_date\": fake.date_this_year(),\n",
    "        \"venue_id\": random.randint(1, venue_num),\n",
    "        \"organizer_id\": random.choice(organizers['user_id'].tolist()),\n",
    "        \"status\": random.choices(statuses, statuses_weights)[0],\n",
    "    })\n",
    "events_df = pd.DataFrame(events)\n",
    "events_df.to_csv(\"events.csv\", index=False)\n",
    "\n",
    "print(events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       venue_id  seat_number     section     row   seat_type\n",
      "0             1            1   Section-7  Row-37     Regular\n",
      "1             1            2  Section-10  Row-15     Regular\n",
      "2             1            3   Section-6  Row-11     Regular\n",
      "3             1            4   Section-1  Row-26     Regular\n",
      "4             1            5   Section-6  Row-16     Regular\n",
      "...         ...          ...         ...     ...         ...\n",
      "19975        20          995   Section-9  Row-35         VIP\n",
      "19976        20          996   Section-4  Row-25     Regular\n",
      "19977        20          997   Section-2  Row-17  Wheelchair\n",
      "19978        20          998   Section-5   Row-2     Regular\n",
      "19979        20          999   Section-6  Row-32     Regular\n",
      "\n",
      "[19980 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Seats\n",
    "seats = []\n",
    "seat_types = [\"Regular\", \"VIP\", \"Wheelchair\"]\n",
    "seat_types_weights = [0.7, 0.2, 0.1]\n",
    "for venue_id in range(1, venue_num + 1):\n",
    "    for seat_number in range(1, 1000):  # 1000 seats per venue\n",
    "        seats.append({\n",
    "            \"venue_id\": venue_id,\n",
    "            \"seat_number\": seat_number,\n",
    "            \"section\": f\"Section-{random.randint(1, 10)}\",\n",
    "            \"row\": f\"Row-{random.randint(1, 40)}\",\n",
    "            \"seat_type\": random.choices(seat_types, seat_types_weights)[0],\n",
    "        })\n",
    "seats_df = pd.DataFrame(seats)\n",
    "seats_df.to_csv(\"seats.csv\", index=False)\n",
    "\n",
    "print(seats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      order_id  user_id  total_amount                 order_date   status\n",
      "0            1      641        482.79 2024-07-12 15:28:16.508385  Pending\n",
      "1            2       18        261.14 2024-08-28 08:30:20.350899  Pending\n",
      "2            3      938        470.86 2024-07-05 03:19:51.555697     Paid\n",
      "3            4      585        510.83 2024-04-05 09:18:53.958235  Pending\n",
      "4            5      681        206.21 2024-11-18 05:27:01.016830  Pending\n",
      "...        ...      ...           ...                        ...      ...\n",
      "1195      1196       77        966.31 2024-04-26 19:14:05.377333     Paid\n",
      "1196      1197      683        780.19 2024-07-18 14:24:31.672278  Pending\n",
      "1197      1198      696        768.58 2024-02-03 11:16:10.702141  Pending\n",
      "1198      1199      639        681.01 2024-10-11 23:46:40.503668     Paid\n",
      "1199      1200      877        569.47 2024-01-15 17:33:22.406843     Paid\n",
      "\n",
      "[1200 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# ORDER\n",
    "user_num = 1000\n",
    "venue_num = 20\n",
    "event_num = 300\n",
    "payment_num = 1400\n",
    "order_num = 1200\n",
    "ticket_num = 1000\n",
    "seat_num = 1000\n",
    "\n",
    "orders = []\n",
    "payments = []\n",
    "tickets = []\n",
    "order_statuses = [\"Pending\", \"Paid\", \"Canceled\"]\n",
    "ticket_statuses = [\"Youth\", \"Adult\", \"Senior\"] # youth, adult, senior\n",
    "payment_methods = [\"Credit Card\", \"PayPal\", \"Bank Transfer\"]\n",
    "payment_statuses = [\"Pending\", \"Completed\", \"Failed\"]\n",
    "payment_statuses_weights = [0.7, 0.2, 0.1]\n",
    "ticket_statuses_weights = [0.7, 0.2, 0.1]\n",
    "order_statuses_weights = [0.7, 0.2, 0.1]\n",
    "for i in range(1, order_num + 1):\n",
    "    orders.append({\n",
    "        \"order_id\": i,\n",
    "        \"user_id\": random.randint(1, user_num),\n",
    "        \"total_amount\": round(random.uniform(100, 1000), 2),\n",
    "        \"order_date\": fake.date_time_this_year(),\n",
    "        \"status\": random.choices(order_statuses, order_statuses_weights)[0],\n",
    "    })\n",
    "    \n",
    "    if (orders[i-1]['status'] == 'Paid'):\n",
    "        total_amount = 0\n",
    "        for j in range(random.randint(1, 5)):\n",
    "            event = random.randint(1, event_num)\n",
    "            ticket = {\n",
    "                \"ticket_id\": len(tickets) + 1,\n",
    "                \"event_id\": event,\n",
    "                \"order_id\": i,\n",
    "                \"venue_id\": 0,\n",
    "                \"seat_number\": 0,\n",
    "                \"price\": round(random.uniform(50, 200), 2),\n",
    "                \"status\": random.choices(ticket_statuses, ticket_statuses_weights)[0],\n",
    "            }\n",
    "            \n",
    "            while True:\n",
    "                seat = random.choice(seats)\n",
    "                if ((seat['venue_id'], seat['seat_number'], event) not in [(t['venue_id'], t['seat_number'], t['event_id']) for t in tickets]):\n",
    "                    ticket['venue_id'] = seat['venue_id']\n",
    "                    ticket['seat_number'] = seat['seat_number']\n",
    "                    break\n",
    "                \n",
    "            tickets.append(ticket)\n",
    "            total_amount += ticket['price']\n",
    "\n",
    "        payment = {\n",
    "            \"payment_id\": len(payments) + 1,\n",
    "            \"order_id\": i,\n",
    "            \"payment_date\": fake.date_time_this_year(),\n",
    "            \"amount\": total_amount,\n",
    "            \"method\": random.choice(payment_methods),\n",
    "            \"status\": \"Completed\",\n",
    "        }\n",
    "        payments.append(payment)\n",
    "    elif (orders[i-1]['status'] == 'Pending'):\n",
    "        payment = {\n",
    "            \"payment_id\": len(payments) + 1,\n",
    "            \"order_id\": i,\n",
    "            \"payment_date\": fake.date_time_this_year(),\n",
    "            \"amount\": orders[i-1]['total_amount'],\n",
    "            \"method\": random.choice(payment_methods),\n",
    "            \"status\": \"Pending\",\n",
    "        }\n",
    "        payments.append(payment)\n",
    "        \n",
    "        \n",
    "orders_df = pd.DataFrame(orders)\n",
    "orders_df.to_csv(\"orders.csv\", index=False)\n",
    "\n",
    "payments_df = pd.DataFrame(payments)\n",
    "payments_df.to_csv(\"payments.csv\", index=False)\n",
    "\n",
    "tickets_df = pd.DataFrame(tickets)\n",
    "tickets_df.to_csv(\"tickets.csv\", index=False)\n",
    "\n",
    "print(orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate seat found, retrying... {'venue_id': 9, 'seat_number': 5, 'section': 'Section-4', 'row': 'Row-40', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 4, 'seat_number': 854, 'section': 'Section-5', 'row': 'Row-29', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 17, 'seat_number': 541, 'section': 'Section-4', 'row': 'Row-8', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 11, 'seat_number': 686, 'section': 'Section-7', 'row': 'Row-18', 'seat_type': 'Wheelchair'}\n",
      "Duplicate seat found, retrying... {'venue_id': 18, 'seat_number': 689, 'section': 'Section-8', 'row': 'Row-12', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 1, 'seat_number': 713, 'section': 'Section-4', 'row': 'Row-35', 'seat_type': 'VIP'}\n",
      "Duplicate seat found, retrying... {'venue_id': 13, 'seat_number': 999, 'section': 'Section-2', 'row': 'Row-8', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 1, 'seat_number': 804, 'section': 'Section-5', 'row': 'Row-38', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 1, 'seat_number': 411, 'section': 'Section-8', 'row': 'Row-11', 'seat_type': 'VIP'}\n",
      "Duplicate seat found, retrying... {'venue_id': 6, 'seat_number': 726, 'section': 'Section-2', 'row': 'Row-5', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 5, 'seat_number': 158, 'section': 'Section-5', 'row': 'Row-7', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 15, 'seat_number': 512, 'section': 'Section-4', 'row': 'Row-27', 'seat_type': 'Wheelchair'}\n",
      "Duplicate seat found, retrying... {'venue_id': 3, 'seat_number': 62, 'section': 'Section-10', 'row': 'Row-31', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 19, 'seat_number': 794, 'section': 'Section-10', 'row': 'Row-9', 'seat_type': 'Wheelchair'}\n",
      "Duplicate seat found, retrying... {'venue_id': 5, 'seat_number': 379, 'section': 'Section-7', 'row': 'Row-9', 'seat_type': 'VIP'}\n",
      "Duplicate seat found, retrying... {'venue_id': 8, 'seat_number': 33, 'section': 'Section-10', 'row': 'Row-25', 'seat_type': 'Wheelchair'}\n",
      "Duplicate seat found, retrying... {'venue_id': 4, 'seat_number': 92, 'section': 'Section-3', 'row': 'Row-24', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 15, 'seat_number': 602, 'section': 'Section-1', 'row': 'Row-11', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 4, 'seat_number': 69, 'section': 'Section-9', 'row': 'Row-8', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 15, 'seat_number': 120, 'section': 'Section-5', 'row': 'Row-15', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 13, 'seat_number': 111, 'section': 'Section-3', 'row': 'Row-38', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 3, 'seat_number': 249, 'section': 'Section-2', 'row': 'Row-1', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 11, 'seat_number': 278, 'section': 'Section-5', 'row': 'Row-25', 'seat_type': 'VIP'}\n",
      "Duplicate seat found, retrying... {'venue_id': 19, 'seat_number': 878, 'section': 'Section-4', 'row': 'Row-20', 'seat_type': 'VIP'}\n",
      "Duplicate seat found, retrying... {'venue_id': 20, 'seat_number': 853, 'section': 'Section-6', 'row': 'Row-11', 'seat_type': 'VIP'}\n",
      "Duplicate seat found, retrying... {'venue_id': 5, 'seat_number': 443, 'section': 'Section-1', 'row': 'Row-20', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 17, 'seat_number': 42, 'section': 'Section-3', 'row': 'Row-13', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 13, 'seat_number': 242, 'section': 'Section-6', 'row': 'Row-3', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 9, 'seat_number': 956, 'section': 'Section-9', 'row': 'Row-6', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 16, 'seat_number': 272, 'section': 'Section-6', 'row': 'Row-8', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 5, 'seat_number': 575, 'section': 'Section-3', 'row': 'Row-31', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 9, 'seat_number': 30, 'section': 'Section-1', 'row': 'Row-16', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 15, 'seat_number': 758, 'section': 'Section-1', 'row': 'Row-21', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 18, 'seat_number': 736, 'section': 'Section-1', 'row': 'Row-5', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 2, 'seat_number': 741, 'section': 'Section-9', 'row': 'Row-23', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 9, 'seat_number': 496, 'section': 'Section-7', 'row': 'Row-10', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 19, 'seat_number': 70, 'section': 'Section-8', 'row': 'Row-20', 'seat_type': 'Wheelchair'}\n",
      "Duplicate seat found, retrying... {'venue_id': 5, 'seat_number': 443, 'section': 'Section-1', 'row': 'Row-20', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 16, 'seat_number': 630, 'section': 'Section-9', 'row': 'Row-33', 'seat_type': 'Wheelchair'}\n",
      "Duplicate seat found, retrying... {'venue_id': 10, 'seat_number': 417, 'section': 'Section-1', 'row': 'Row-29', 'seat_type': 'Regular'}\n",
      "Duplicate seat found, retrying... {'venue_id': 15, 'seat_number': 173, 'section': 'Section-2', 'row': 'Row-39', 'seat_type': 'Regular'}\n",
      "Fake data generated and saved to CSV files:\n",
      "Seats:    venue_id  seat_number     section     row   seat_type\n",
      "0         1            1  Section-10  Row-32     Regular\n",
      "1         1            2  Section-10  Row-19  Wheelchair\n",
      "2         1            3   Section-9   Row-8     Regular\n",
      "3         1            4   Section-9  Row-33     Regular\n",
      "4         1            5   Section-8  Row-11         VIP\n",
      "Orders:    order_id  user_id  total_amount                 order_date    status\n",
      "0         1      792        577.53 2024-05-31 19:39:14.039099  Canceled\n",
      "1         2      987        708.97 2024-03-26 14:03:28.436472   Pending\n",
      "2         3      180        706.34 2024-07-30 20:08:41.717982   Pending\n",
      "3         4        7        701.94 2024-02-23 03:39:59.655737   Pending\n",
      "4         5      634        982.05 2024-05-24 23:07:00.129050  Canceled\n",
      "Tickets:    ticket_id  event_id  venue_id  seat_number   price     status\n",
      "0          1       239        18          859  147.53  Available\n",
      "1          2        44         2          741   52.13       Sold\n",
      "2          3        39        11          402   90.91       Sold\n",
      "3          4        34         3           50   56.64       Sold\n",
      "4          5       258        11          565   56.83  Available\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from faker import Faker\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "# Configuration\n",
    "venue_num = 20\n",
    "section_num = 5\n",
    "seat_num_per_section = 150\n",
    "\n",
    "order_num = 1200\n",
    "ticket_num = 1000\n",
    "\n",
    "# Generate Order Data\n",
    "orders = []\n",
    "for i in range(1, order_num + 1):\n",
    "    orders.append({\n",
    "        \"order_id\": i,\n",
    "        \"user_id\": random.randint(1, 1000),\n",
    "        \"total_amount\": round(random.uniform(100, 1000), 2),\n",
    "        \"order_date\": fake.date_time_this_year(),\n",
    "        \"status\": random.choice([\"Pending\", \"Paid\", \"Canceled\"]),\n",
    "    })\n",
    "\n",
    "# Generate Ticket Data\n",
    "tickets = []\n",
    "for order in orders:\n",
    "    if order[\"status\"] == \"Paid\":\n",
    "        for _ in range(random.randint(1, 5)):  # Each order gets 1-5 tickets\n",
    "            seat = random.choice(seats)\n",
    "\n",
    "            tickets.append({\n",
    "                \"ticket_id\": len(tickets) + 1,\n",
    "                \"event_id\": random.randint(1, 300),\n",
    "                \"venue_id\": seat[\"venue_id\"],\n",
    "                \"seat_number\": seat[\"seat_number\"],\n",
    "                \"price\": round(random.uniform(50, 200), 2),\n",
    "                \"status\": random.choice([\"Available\", \"Reserved\", \"Sold\"])\n",
    "            })\n",
    "\n",
    "# Convert to DataFrames\n",
    "seats_df = pd.DataFrame(seats)\n",
    "orders_df = pd.DataFrame(orders)\n",
    "tickets_df = pd.DataFrame(tickets)\n",
    "\n",
    "# Save to CSV\n",
    "seats_df.to_csv(\"seats.csv\", index=False)\n",
    "orders_df.to_csv(\"orders.csv\", index=False)\n",
    "tickets_df.to_csv(\"tickets.csv\", index=False)\n",
    "\n",
    "print(\"Fake data generated and saved to CSV files:\")\n",
    "print(\"Seats:\", seats_df.head())\n",
    "print(\"Orders:\", orders_df.head())\n",
    "print(\"Tickets:\", tickets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if every ticket has only appear once in every seat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
